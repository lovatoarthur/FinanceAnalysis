{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0247cfeb",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "In this project, I wanted to train a classifier model to receive sentences as inputs and be able to correctly output a sentiment (positive, negative, or neutral) that is expressed in the sentence. To achieve that, I used a labeled data set of sentences, cleaned it, used the Doc2Vec algorithm to vectorize the sentences, and then trained and tested different classification models. \n",
    "\n",
    "Throughout the project, I saw that with default parameters for support vector classifier and logistic regression the size of the output vector from Doc2Vec didn’t present a big impact on classification performance. Furthermore, I saw that SVC performance increased from about 62% accuracy to 72% when we balanced the dataset by oversampling the smaller classes. In addition to that, when searching for the best parameters, I found out that the best ones were the default.\n",
    "\n",
    "To conclude, this project was great to learn more about NLP algorithms, such as Doc2Vec and Word2Vec, especially the particularities related to coding it in Python. It was also interesting to review some of the most common classifiers available on sklearn package and how to optimize them to achieve the best results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba7f06b",
   "metadata": {},
   "source": [
    "### Importing packages, loading data and creating functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cd3f07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd               # Library for reading files \n",
    "import string                     # working with strings\n",
    "import re                         # regular expressions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk                       # Natural Language Toolkit\n",
    "from nltk.corpus import stopwords # stop words\n",
    "from nltk.stem.porter import PorterStemmer # PoterStemmer\n",
    "from nltk.corpus import wordnet            # Wordnet\n",
    "from nltk.stem import WordNetLemmatizer    # lemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from collections import Counter            # \n",
    "\n",
    "import gensim #vectorization package\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument #vectorization neural net \n",
    "from gensim.models import Word2Vec #vectorization neural net\n",
    "from gensim.models.phrases import Phrases, Phraser #phraser do collect bigrams\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5dd6e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('unprocessed data.csv', sep=';', encoding='latin-1',header =0)\n",
    "#print(data.shape)\n",
    "#print(\"COLUMN NAMES\" , data.columns)\n",
    "#print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88636897",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "wordnet_map = {\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV}\n",
    "\n",
    "def brief_cleaning(text):\n",
    "    \"\"\"makes all text lower case and removes punctuation\"\"\"\n",
    "    \n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0-9]+', '', text).lower()\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text, STOPWORDS):\n",
    "    \"\"\"custom function to remove the stopwords\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "def stem_words(text, stemmer):\n",
    "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "def lemmatize_words(text, lemmatizer, wordnet_map ):\n",
    "    pos_tagged_text = nltk.pos_tag(text.split())\n",
    "    return \" \".join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "778bc8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_docs(x):\n",
    "    \"\"\"this function takes a list of lists (each word in an element on the inside list) and returns a tagged document, \n",
    "    that is necessary for the doc2vec model\"\"\"\n",
    "    \n",
    "    return [TaggedDocument(words=_d, tags=[str(i)]) for i, _d in enumerate(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cd40571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_doc2vec_model(tagged_docs, vector_size, min_count):\n",
    "    \"\"\"this functions tkaes the tagged documents, vector_size and min_count and returns the model trained.\n",
    "    The model can be used to predict the vectors of the documents on the training and testing set\n",
    "    \n",
    "    vector_size =  Dimensionality of the feature vectors.\n",
    "    min_count =  Ignores all words with total frequency lower than this.\n",
    "    \"\"\"\n",
    "    \n",
    "    doc2vec_model = Doc2Vec(vector_size=vector_size, min_count=min_count, epochs=40)\n",
    "    doc2vec_model.build_vocab(tagged_docs)\n",
    "    doc2vec_model.train(tagged_docs, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)\n",
    "    \n",
    "    return doc2vec_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee55da9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_vectors(doc2vec_model, docs):\n",
    "    \"\"\"this function takes the model and a list of documents (where each document is a list of words) and\n",
    "    returns the predicted vector for it\"\"\"\n",
    "    \n",
    "    vectors = []\n",
    "    for vec in docs:\n",
    "        vectors.append(doc2vec_model.infer_vector(vec))\n",
    "        \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cac209",
   "metadata": {},
   "source": [
    "### Pre-processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8d008f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctuation and make all lower case\n",
    "data['Sentence'] = data['Sentence'].apply(lambda text: brief_cleaning(text))\n",
    "\n",
    "#remove first set of stopwords\n",
    "data['Sentence'] = data['Sentence'].apply(lambda text: remove_stopwords(text, STOPWORDS))\n",
    "\n",
    "#remove second set of stopwords\n",
    "data['Sentence'] = data['Sentence'].apply(lambda text: remove_stopwords(text, stopword))\n",
    "\n",
    "#applying lemmatize\n",
    "data['Sentence'] = data['Sentence'].apply(lambda text: lemmatize_words(text, lemmatizer, wordnet_map))\n",
    "\n",
    "#selecting the words in the sentences\n",
    "sents = [row.split(' ') for row in data['Sentence']]\n",
    "\n",
    "#select bigram\n",
    "phrases = Phrases(sents, min_count=30, progress_per=10000)\n",
    "bigram = Phraser(phrases)\n",
    "sentences = bigram[sents]\n",
    "\n",
    "#set x as a list of documents, where each document is a list of words\n",
    "x = sentences\n",
    "\n",
    "#Convert sting to numeric\n",
    "sentiment  = {'positive': 0,'neutral': 1,'negative':2} \n",
    "y = [sentiment[item] for item in data.Sentiment] \n",
    "#y = data.Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0853c87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#here we plot the data and we can see that the data is unbalanced... later in the analysis we will try to balance it\n",
    "data.Sentiment.value_counts().plot(kind = 'bar')\n",
    "plt.title('Number of observations for each class')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb681161",
   "metadata": {},
   "source": [
    "### Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c61b2b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we divide the data into training and testing - usage of stratify to keep the balance.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "20fd7cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd we have to set x_train as a tagged doc, bc it will be used to train the doc2vec\n",
    "x_train_tagged = tag_docs(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a7bef0",
   "metadata": {},
   "source": [
    "`X = df_new['essay_content']`\n",
    "\n",
    "`y = df_new['label']`\n",
    "\n",
    "`X_train, X_test, y_train, y_test = train_test_split(X, y)`\n",
    "\n",
    "`vectorizer = TfidfVectorizer(stop_words='english')`\n",
    "\n",
    "`X_train_dtm = vectorizer.fit_transform(X_train)`\n",
    "\n",
    "`X_test_dtm = vectorizer.transform(X_test)`\n",
    "\n",
    "`clf_lr = LogisticRegression()`\n",
    "\n",
    "`clf_lr.fit(X_train_dtm, y_train)`\n",
    "\n",
    "`y_pred = clf_lr.predict(X_test_dtm)`\n",
    "\n",
    "\n",
    "\"In the code example above we would split the document set into training and testing, and then use ONLY training documents to build the term collection. This way, we are making sure that the classifier trained on the training tf-idf matrix is generalizing well.\n",
    "\n",
    "Therefore, I feel that doc2vec workflow should follow the same general principal, i.e. to train (build vocabulary) the doc2vec ONLY using training documents\"\n",
    "\n",
    "- source: https://fzr72725.github.io/2018/01/14/genism-guide.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0782d653",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we will train the doc2vec on the training data\n",
    "doc2vec_model = train_doc2vec_model(x_train_tagged, vector_size = 50, min_count = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "69f1b32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we will infer the vector values for for x_train and x_test.\n",
    "#we have to use the un-tagged x_train\n",
    "x_train_vectors = infer_vectors(doc2vec_model, x_train)\n",
    "x_test_vectors = infer_vectors(doc2vec_model, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7621253",
   "metadata": {},
   "source": [
    "\"This is one of the most confusing parts for me in the doc2vec training process. Many code examples did not use infer_vector() to “retrain” the document vectors. Instead, they used the trained vectors from the doc2vec_model directly as the final vector matrix. I think this is also one of the motivations for people to assign a unique tag to each document as I mentioned earlier.\n",
    "\n",
    "I personally found it more reasonable to use infer_vector() to “retrain” the document vector. Reason being: “You could certainly use the vectors learned during training. But note that during much of their 20-training-passes, the model itself was still undergoing rapid change, and was far from its final state. I’ve sometimes seen that re-inferred vectors, often work better for downstream tasks. This is perhaps because then all 20-inference-passes, across all re-inferred vectors, equally benefit from the same final frozen model state”, quoted Gordon Mohr from a Google group Q&A.\"\n",
    "\n",
    "- source: https://fzr72725.github.io/2018/01/14/genism-guide.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2df7d21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.62069\n"
     ]
    }
   ],
   "source": [
    "#now that we have both x_train and x_test vectorized we can train our classification model\n",
    "\n",
    "lr_not_os = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "lr_not_os.fit(x_train_vectors, y_train)\n",
    "\n",
    "y_pred_not_os = lr_not_os.predict(x_test_vectors)\n",
    "\n",
    "print ('Test Accuracy: %.5f'%lr_not_os.score(x_test_vectors, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "58bf0e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46827017963036405"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "recall_score(y_test, y_pred_not_os, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4f2a6ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[163, 191,  12],\n",
       "       [ 72, 541,  13],\n",
       "       [ 57,  95,  16]], dtype=int64)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_not_os)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb4f4b3",
   "metadata": {},
   "source": [
    "### Trying to optimize the vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "527aeab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.59138\n",
      "Vector size: 10\n",
      "[[145 203  18]\n",
      " [ 90 518  18]\n",
      " [ 48  97  23]]\n",
      "time: 22.619375228881836\n",
      "\n",
      "\n",
      "Test Accuracy: 0.59310\n",
      "Vector size: 50\n",
      "[[152 197  17]\n",
      " [ 91 515  20]\n",
      " [ 56  91  21]]\n",
      "time: 47.930750131607056\n",
      "\n",
      "\n",
      "Test Accuracy: 0.58966\n",
      "Vector size: 90\n",
      "[[147 204  15]\n",
      " [ 88 518  20]\n",
      " [ 49 100  19]]\n",
      "time: 71.18521165847778\n",
      "\n",
      "\n",
      "Test Accuracy: 0.59310\n",
      "Vector size: 130\n",
      "[[153 198  15]\n",
      " [ 92 514  20]\n",
      " [ 53  94  21]]\n",
      "time: 93.72764587402344\n",
      "\n",
      "\n",
      "Test Accuracy: 0.60000\n",
      "Vector size: 170\n",
      "[[157 193  16]\n",
      " [ 87 520  19]\n",
      " [ 55  94  19]]\n",
      "time: 116.14655804634094\n",
      "\n",
      "\n",
      "Test Accuracy: 0.59914\n",
      "Vector size: 210\n",
      "[[154 193  19]\n",
      " [ 89 518  19]\n",
      " [ 51  94  23]]\n",
      "time: 138.5702829360962\n",
      "\n",
      "\n",
      "Test Accuracy: 0.59052\n",
      "Vector size: 250\n",
      "[[150 199  17]\n",
      " [ 89 515  22]\n",
      " [ 53  95  20]]\n",
      "time: 161.23874926567078\n",
      "\n",
      "\n",
      "Test Accuracy: 0.58966\n",
      "Vector size: 290\n",
      "[[145 204  17]\n",
      " [ 87 520  19]\n",
      " [ 55  94  19]]\n",
      "time: 183.96789002418518\n",
      "\n",
      "\n",
      "Test Accuracy: 0.58879\n",
      "Vector size: 330\n",
      "[[146 202  18]\n",
      " [ 92 517  17]\n",
      " [ 49  99  20]]\n",
      "time: 207.43958568572998\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now I'll try to optimize the vector size, doing a loop between 50 and 300\n",
    "vect_sizes = np.arange(10, 350, 40)\n",
    "models = []\n",
    "scores = []\n",
    "conf_matrixes = []\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "for vec in vect_sizes:\n",
    "    #initiate and train the model\n",
    "    model = train_doc2vec_model(x_train_tagged, vector_size = vec, min_count = 1)\n",
    "    #predict training vectors\n",
    "    x_train_vectors = infer_vectors(doc2vec_model, x_train)\n",
    "    #predict testing vectors\n",
    "    x_test_vectors = infer_vectors(doc2vec_model, x_test)\n",
    "    #initiate classification model\n",
    "    lr = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "    #fit training values\n",
    "    lr.fit(x_train_vectors, y_train)\n",
    "    \n",
    "    models.append(model)\n",
    "    scores.append(lr.score(x_test_vectors, y_test))\n",
    "    conf_matrixes.append(confusion_matrix(y_test, lr.predict(x_test_vectors)))\n",
    "    \n",
    "    #print score, vector size and how long it took\n",
    "    print ('Test Accuracy: %.5f'%lr.score(x_test_vectors, y_test))\n",
    "    print('Vector size: ' + str(vec))\n",
    "    print(confusion_matrix(y_test, lr.predict(x_test_vectors)))\n",
    "    print('time: ' + str(time.time()-start))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5960612c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x = vect_sizes, y = scores, color= 'gray')\n",
    "plt.ylim(0,1)\n",
    "plt.title('Vector size influence on model accuracy')\n",
    "plt.xlabel('vector size')\n",
    "plt.ylabel('LogReg accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178e8d64",
   "metadata": {},
   "source": [
    "Looks like the size doesnt influence as much, we can see that the model doesnt perform good on positive and negatives, so lets try to resample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a04ff6",
   "metadata": {},
   "source": [
    "### Testing Oversampling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "00ef5719",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing oversampling the data to get better accuracy\n",
    "class_positive = data[data['Sentiment'] == 'positive']\n",
    "class_negative = data[data['Sentiment'] == 'negative']\n",
    "class_neutral = data[data['Sentiment'] == 'neutral']\n",
    "\n",
    "class_count_neutral, class_count_positive, class_count_negative = data.Sentiment.value_counts()\n",
    "\n",
    "class_positive_over = class_positive.sample(class_count_neutral, replace = True)\n",
    "class_negative_over = class_negative.sample(class_count_neutral, replace = True)\n",
    "\n",
    "data_oversampled = pd.concat([class_positive_over, class_negative_over, class_neutral], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "97a4fe8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#now we can see that they all have the same amount of samples\n",
    "data_oversampled.Sentiment.value_counts().plot(kind='bar')\n",
    "plt.title('Number of observations for each class')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b000a9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doing some pre-processing again\n",
    "\n",
    "#selecting the words in the sentences\n",
    "sents = [row.split(' ') for row in data['Sentence']]\n",
    "sents_over = [row.split(' ') for row in data_oversampled['Sentence']]\n",
    "\n",
    "#select bigram\n",
    "phrases = Phrases(sents, min_count=30, progress_per=10000)\n",
    "bigram = Phraser(phrases)\n",
    "sentences_over = bigram[sents_over]\n",
    "\n",
    "#set x as a list of documents, where each document is a list of words\n",
    "x_over = sentences_over\n",
    "\n",
    "#Convert sting to numeric\n",
    "sentiment  = {'positive': 0,'neutral': 1,'negative':2} \n",
    "y_over = [sentiment[item] for item in data_oversampled.Sentiment] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a4287f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.56230\n"
     ]
    }
   ],
   "source": [
    "#first we divide the data into training and testing - usage of stratify to keep the balance.\n",
    "x_train_over, x_test_over, y_train_over, y_test_over = train_test_split(x_over, y_over, test_size = 0.2, stratify = y_over)\n",
    "\n",
    "#2nd we have to set x_train as a tagged doc, bc it will be used to train the doc2vec\n",
    "x_train_tagged_over = tag_docs(x_train_over)\n",
    "\n",
    "#now we will train the doc2vec on the training data\n",
    "doc2vec_model = train_doc2vec_model(x_train_tagged_over, vector_size = 50, min_count = 1)\n",
    "\n",
    "#here we will infer the vector values for for x_train and x_test.\n",
    "#we have to use the un-tagged x_train\n",
    "x_train_vectors_over = infer_vectors(doc2vec_model, x_train_over)\n",
    "x_test_vectors_over = infer_vectors(doc2vec_model, x_test_over)\n",
    "\n",
    "#now that we have both x_train and x_test vectorized we can train our classification model\n",
    "lr_over = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "lr_over.fit(x_train_vectors_over, y_train_over)\n",
    "print ('Test Accuracy: %.5f'%lr_over.score(x_test_vectors_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "31735c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[328, 161, 137],\n",
       "       [101, 400, 125],\n",
       "       [146, 152, 328]], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test_over, lr.predict(x_test_vectors_over))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67b872a",
   "metadata": {},
   "source": [
    "Overall performance decreased, but the model predicts better positives and negatives (but this can happens bc we have the same data in training and testing - bc we oversampled with copies - so it can be overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "025d6917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.56763\n",
      "Vector size: 10\n",
      "[[299 181 146]\n",
      " [103 408 115]\n",
      " [151 116 359]]\n",
      "time: 37.60954976081848\n",
      "\n",
      "\n",
      "Test Accuracy: 0.56443\n",
      "Vector size: 50\n",
      "[[303 173 150]\n",
      " [113 403 110]\n",
      " [144 128 354]]\n",
      "time: 73.83449745178223\n",
      "\n",
      "\n",
      "Test Accuracy: 0.56390\n",
      "Vector size: 90\n",
      "[[300 173 153]\n",
      " [108 404 114]\n",
      " [143 128 355]]\n",
      "time: 110.89501166343689\n",
      "\n",
      "\n",
      "Test Accuracy: 0.56390\n",
      "Vector size: 130\n",
      "[[298 173 155]\n",
      " [107 404 115]\n",
      " [147 122 357]]\n",
      "time: 148.92317652702332\n",
      "\n",
      "\n",
      "Test Accuracy: 0.56763\n",
      "Vector size: 170\n",
      "[[312 160 154]\n",
      " [110 400 116]\n",
      " [131 141 354]]\n",
      "time: 186.30771350860596\n",
      "\n",
      "\n",
      "Test Accuracy: 0.57135\n",
      "Vector size: 210\n",
      "[[296 178 152]\n",
      " [107 412 107]\n",
      " [137 124 365]]\n",
      "time: 223.3817641735077\n",
      "\n",
      "\n",
      "Test Accuracy: 0.57188\n",
      "Vector size: 250\n",
      "[[303 164 159]\n",
      " [106 414 106]\n",
      " [144 125 357]]\n",
      "time: 263.93087458610535\n",
      "\n",
      "\n",
      "Test Accuracy: 0.57029\n",
      "Vector size: 290\n",
      "[[301 179 146]\n",
      " [104 404 118]\n",
      " [142 118 366]]\n",
      "time: 302.46192240715027\n",
      "\n",
      "\n",
      "Test Accuracy: 0.56017\n",
      "Vector size: 330\n",
      "[[298 180 148]\n",
      " [108 400 118]\n",
      " [145 127 354]]\n",
      "time: 339.08267307281494\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now I'll try to optimize the vector size, doing a loop between 50 and 300\n",
    "vect_sizes = np.arange(10, 350, 40)\n",
    "models_os = []\n",
    "scores_os = []\n",
    "conf_matrixes_os = []\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "for vec in vect_sizes:\n",
    "    #initiate and train the model\n",
    "    model = train_doc2vec_model(x_train_tagged_over, vector_size = vec, min_count = 1)\n",
    "    #predict training vectors\n",
    "    x_train_vectors_over = infer_vectors(doc2vec_model, x_train_over)\n",
    "    #predict testing vectors\n",
    "    x_test_vectors_over = infer_vectors(doc2vec_model, x_test_over)\n",
    "    #initiate classification model\n",
    "    lr = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "    #fit training values\n",
    "    lr.fit(x_train_vectors_over, y_train_over)\n",
    "    \n",
    "    models_os.append(model)\n",
    "    scores_os.append(lr.score(x_test_vectors_over, y_test_over))\n",
    "    conf_matrixes_os.append(confusion_matrix(y_test_over, lr.predict(x_test_vectors_over)))\n",
    "    \n",
    "    #print score, vector size and how long it took\n",
    "    print ('Test Accuracy: %.5f'%lr.score(x_test_vectors_over, y_test_over))\n",
    "    print('Vector size: ' + str(vec))\n",
    "    print(confusion_matrix(y_test, lr.predict(x_test_vectors_over)))\n",
    "    print('time: ' + str(time.time()-start))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44d8d40",
   "metadata": {},
   "source": [
    "### Test scalling the vectors before classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "08172ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.58520\n"
     ]
    }
   ],
   "source": [
    "#first we divide the data into training and testing - usage of stratify to keep the balance.\n",
    "x_train_over, x_test_over, y_train_over, y_test_over = train_test_split(x_over, y_over, test_size = 0.2, stratify = y_over)\n",
    "\n",
    "#2nd we have to set x_train as a tagged doc, bc it will be used to train the doc2vec\n",
    "x_train_tagged_over = tag_docs(x_train_over)\n",
    "\n",
    "#now we will train the doc2vec on the training data\n",
    "doc2vec_model = train_doc2vec_model(x_train_tagged_over, vector_size = 50, min_count = 1)\n",
    "\n",
    "#here we will infer the vector values for for x_train and x_test.\n",
    "#we have to use the un-tagged x_train\n",
    "x_train_vectors_over = infer_vectors(doc2vec_model, x_train_over)\n",
    "x_test_vectors_over = infer_vectors(doc2vec_model, x_test_over)\n",
    "\n",
    "x_train_vectors_over = scale(x_train_vectors_over)\n",
    "x_test_vectors_over = scale(x_test_vectors_over)\n",
    "\n",
    "#now that we have both x_train and x_test vectorized we can train our classification model\n",
    "lr = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "lr.fit(x_train_vectors_over, y_train_over)\n",
    "print ('Test Accuracy: %.5f'%lr.score(x_test_vectors_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "719b2497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[123,  80, 163],\n",
       "       [255, 138, 233],\n",
       "       [ 57,  35,  76]], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, lr.predict(x_test_vectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ef342e",
   "metadata": {},
   "source": [
    "### Testing different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "00b2baf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "999685cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we divide the data into training and testing - usage of stratify to keep the balance.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, stratify = y)\n",
    "\n",
    "#2nd we have to set x_train as a tagged doc, bc it will be used to train the doc2vec\n",
    "x_train_tagged = tag_docs(x_train)\n",
    "\n",
    "#now we will train the doc2vec on the training data\n",
    "doc2vec_model = train_doc2vec_model(x_train_tagged, vector_size = 50, min_count = 1)\n",
    "\n",
    "#here we will infer the vector values for for x_train and x_test.\n",
    "#we have to use the un-tagged x_train\n",
    "x_train_vectors = infer_vectors(doc2vec_model, x_train)\n",
    "x_test_vectors = infer_vectors(doc2vec_model, x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "df58b90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(multi_class='multinomial'),\n",
       "             param_grid={'class_weight': [None, 'balanced'],\n",
       "                         'solver': ['newton-cg', 'sag', 'saga', 'lbfgs']})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#changing the parameters on the logistic regression\n",
    "\n",
    "params_lr = {'solver':['newton-cg', 'sag', 'saga', 'lbfgs'],\n",
    "         'class_weight':[None, 'balanced']}\n",
    "\n",
    "lr = LogisticRegression(multi_class='multinomial')\n",
    "\n",
    "gs_lr = GridSearchCV(lr, params_lr)\n",
    "\n",
    "gs_lr.fit(x_train_vectors, y_train)\n",
    "\n",
    "#print ('Test Accuracy: %.5f'%gs_lr.score(x_test_vectors, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d413a77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': None, 'solver': 'newton-cg'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best estimator\n",
    "best_lr = gs_lr.best_estimator_\n",
    "\n",
    "gs_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5861f0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.60172\n"
     ]
    }
   ],
   "source": [
    "print ('Test Accuracy: %.5f'%best_lr.score(x_test_vectors, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4e6f2028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'class_weight': [None, 'balanced'],\n",
       "                         'decision_function_shape': ['ovo', 'ovr']})"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#search params on SVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "params_svc = {'class_weight':[None, 'balanced'],\n",
    "             'decision_function_shape':['ovo', 'ovr']}\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "gs_svc = GridSearchCV(svc, params_svc)\n",
    "\n",
    "gs_svc.fit(x_train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "270319ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': None, 'decision_function_shape': 'ovo'}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best estimator\n",
    "best_svc = gs_svc.best_estimator_\n",
    "\n",
    "gs_svc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8073f07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.64138\n"
     ]
    }
   ],
   "source": [
    "print ('Test Accuracy: %.5f'%best_svc.score(x_test_vectors, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "21d0b6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svc = best_svc.predict(x_test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "624dd1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[167, 198,   1],\n",
       "       [ 51, 571,   4],\n",
       "       [ 56, 106,   6]], dtype=int64)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a9d8209f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4706896551724138"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trying naive bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "gnb.fit(x_train_vectors, y_train)\n",
    "gnb.score(x_test_vectors, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "99c9129e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5956896551724138"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trying random forest class\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(max_depth=20, random_state=0)\n",
    "\n",
    "rfc.fit(x_train_vectors, y_train)\n",
    "rfc.score(x_test_vectors, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4581fa3",
   "metadata": {},
   "source": [
    "The best model was SVC without class_weight and oVo approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "32a6b022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[165, 196,   5],\n",
       "       [ 50, 564,  12],\n",
       "       [ 57, 107,   4]], dtype=int64)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, best_svc.predict(x_test_vectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ba9220",
   "metadata": {},
   "source": [
    "### Testing SVC with oversampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3d53b5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.72684\n"
     ]
    }
   ],
   "source": [
    "#first we divide the data into training and testing - usage of stratify to keep the balance.\n",
    "x_train_over, x_test_over, y_train_over, y_test_over = train_test_split(x_over, y_over, test_size = 0.2, stratify = y_over)\n",
    "\n",
    "#2nd we have to set x_train as a tagged doc, bc it will be used to train the doc2vec\n",
    "x_train_tagged_over = tag_docs(x_train_over)\n",
    "\n",
    "#now we will train the doc2vec on the training data\n",
    "doc2vec_model = train_doc2vec_model(x_train_tagged_over, vector_size = 50, min_count = 1)\n",
    "\n",
    "#here we will infer the vector values for for x_train and x_test.\n",
    "#we have to use the un-tagged x_train\n",
    "x_train_vectors_over = infer_vectors(doc2vec_model, x_train_over)\n",
    "x_test_vectors_over = infer_vectors(doc2vec_model, x_test_over)\n",
    "\n",
    "#now that we have both x_train and x_test vectorized we can train our classification model\n",
    "svc = SVC()\n",
    "svc.fit(x_train_vectors_over, y_train_over)\n",
    "print ('Test Accuracy: %.5f'%svc.score(x_test_vectors_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b00ad387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[395, 107, 124],\n",
       "       [ 52, 443, 131],\n",
       "       [ 46,  53, 527]], dtype=int64)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test_over, svc.predict(x_test_vectors_over))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539d2ee9",
   "metadata": {},
   "source": [
    "### Searching for the best params for SVC with oversampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d5a433fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'class_weight': [None, 'balanced'],\n",
       "                         'decision_function_shape': ['ovo', 'ovr']})"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#search params on SVC\n",
    "params_svc = {'class_weight':[None, 'balanced'],\n",
    "             'decision_function_shape':['ovo', 'ovr']}\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "gs_svc = GridSearchCV(svc, params_svc)\n",
    "\n",
    "gs_svc.fit(x_train_vectors_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bc97cec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': None, 'decision_function_shape': 'ovo'}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best estimator\n",
    "best_svc = gs_svc.best_estimator_\n",
    "\n",
    "gs_svc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e10a2392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.72737\n"
     ]
    }
   ],
   "source": [
    "print ('Test Accuracy: %.5f'%best_svc.score(x_test_vectors_over, y_test_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "119dc373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.79225\n"
     ]
    }
   ],
   "source": [
    "print ('Train Accuracy: %.5f'%best_svc.score(x_train_vectors_over, y_train_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5f54e844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[384,  44,  43],\n",
       "       [149, 456,  57],\n",
       "       [ 93, 126, 526]], dtype=int64)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(best_svc.predict(x_test_vectors_over), y_test_over)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08211018",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The SVC with oversampled data presented the best performance! - searching for best params didnt optimize it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
